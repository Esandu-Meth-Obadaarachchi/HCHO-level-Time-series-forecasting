{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCAD1JSg5yy7D9/DMFKk+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esandu-Meth-Obadaarachchi/HCHO-level-Time-series-forecasting/blob/main/DE_2_NASA_DATASET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XpvEheuGcHZB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QsfeOMQcNZg",
        "outputId": "cd8e1dad-d2e9-4502-b686-fc7cc3d532aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=9fd38a700e2a1972b01c1811a9ab9981f6b387b13577d2105c0a2161da475615\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHkwH8_DcNbj",
        "outputId": "147fa686-a0af-429a-e981-ac08ecb1dc2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql  as pyspark_sql\n",
        "import pyspark.sql.types as pyspark_types\n",
        "import pyspark.sql.functions  as pyspark_functions\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.functions import col, regexp_replace, when\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, StringType"
      ],
      "metadata": {
        "id": "RUs1TITdcNdo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = pyspark_sql.SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "z1aHKSW5cNe7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_csv_path = '/content/drive/MyDrive/data engineering CW/colombo_df.csv'\n",
        "deniyaya_matara_csv_path = '/content/drive/MyDrive/data engineering CW/deniyaya_matara_df.csv'\n",
        "nuwara_eliya_csv_path = '/content/drive/MyDrive/data engineering CW/nuwara_eliya_df.csv'\n",
        "bibile_monaragala_csv_path = '/content/drive/MyDrive/data engineering CW/bibile_monaragala_df.csv'\n",
        "kurunegala_csv_path = '/content/drive/MyDrive/data engineering CW/kurunegala_df.csv'\n",
        "jaffna_csv_path = '/content/drive/MyDrive/data engineering CW/jaffna_df.csv'\n",
        "kandy_csv_path = '/content/drive/MyDrive/data engineering CW/kandy_df.csv'"
      ],
      "metadata": {
        "id": "lOzZ9owncNgw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_df = spark.read.csv(colombo_csv_path,header = True)\n",
        "deniyaya_matara_df = spark.read.csv(deniyaya_matara_csv_path,header = True)\n",
        "nuwara_eliya_df = spark.read.csv(nuwara_eliya_csv_path,header = True)\n",
        "bibile_monaragala_df = spark.read.csv(bibile_monaragala_csv_path,header = True)\n",
        "jaffna_df = spark.read.csv(jaffna_csv_path,header = True)\n",
        "kandy_df = spark.read.csv(kandy_csv_path ,header = True)\n",
        "kurunegala_df=spark.read.csv(kurunegala_csv_path,header = True)"
      ],
      "metadata": {
        "id": "XxntYDTBcNiW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q5S-GKNcNj4",
        "outputId": "da286b5c-68f5-4c28-db3d-220f3720fe25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+----------+--------------------+\n",
            "|      Location|Current Date| Next Date|        HCHO reading|\n",
            "+--------------+------------+----------+--------------------+\n",
            "|Colombo Proper|  2019-01-01|2019-01-02|1.969834395781014...|\n",
            "|Colombo Proper|  2019-01-02|2019-01-03|2.625522171968594...|\n",
            "|Colombo Proper|  2019-01-03|2019-01-04|9.852118897938794E-5|\n",
            "|Colombo Proper|  2019-01-04|2019-01-05|2.099320518114242E-4|\n",
            "|Colombo Proper|  2019-01-05|2019-01-06|1.785337298892930...|\n",
            "|Colombo Proper|  2019-01-06|2019-01-07|1.082296700235670...|\n",
            "|Colombo Proper|  2019-01-07|2019-01-08|3.926829280477309...|\n",
            "|Colombo Proper|  2019-01-08|2019-01-09|9.153156350685351E-5|\n",
            "|Colombo Proper|  2019-01-09|2019-01-10|1.205978992853015...|\n",
            "|Colombo Proper|  2019-01-10|2019-01-11|1.297723562983258...|\n",
            "|Colombo Proper|  2019-01-11|2019-01-12|2.239188166801278...|\n",
            "|Colombo Proper|  2019-01-12|2019-01-13|1.569418094178759...|\n",
            "|Colombo Proper|  2019-01-13|2019-01-14|1.569418094178759...|\n",
            "|Colombo Proper|  2019-01-14|2019-01-15|1.336291906862603...|\n",
            "|Colombo Proper|  2019-01-15|2019-01-16|6.374417842690063E-5|\n",
            "|Colombo Proper|  2019-01-16|2019-01-17|1.181062250815020...|\n",
            "|Colombo Proper|  2019-01-17|2019-01-18|2.472555222423037...|\n",
            "|Colombo Proper|  2019-01-18|2019-01-19|3.667525352047757E-5|\n",
            "|Colombo Proper|  2019-01-19|2019-01-20|4.057500868150313E-4|\n",
            "|Colombo Proper|  2019-01-20|2019-01-21|1.687856216479722...|\n",
            "+--------------+------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/colombo_data.csv\",header = True)"
      ],
      "metadata": {
        "id": "C1gEVCCWcNls"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Yt_S5hsk2B",
        "outputId": "f3816904-2eac-4828-9a1a-3fd1d26b7701"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+-----+-----+-----------+-----+------+------+-----+---------+-------+-------+-----------------+\n",
            "|YEAR|DOY| QV2M| RH2M|PRECTOTCORR|  T2M|T2MDEW|T2MWET|   TS|T2M_RANGE|T2M_MAX|T2M_MIN|ALLSKY_SFC_LW_DWN|\n",
            "+----+---+-----+-----+-----------+-----+------+------+-----+---------+-------+-------+-----------------+\n",
            "|2019|  1|15.62|   80|       0.12| 24.8| 21.02| 22.91|25.29|     6.21|  28.44|  22.23|           407.15|\n",
            "|2019|  2|15.14| 79.5|       0.02|24.39| 20.51| 22.45|25.01|     6.54|  28.02|  21.48|           401.33|\n",
            "|2019|  3|14.77| 78.5|       0.01|24.17| 20.08| 22.13|24.73|     6.64|  27.94|   21.3|           395.24|\n",
            "|2019|  4|14.47|77.62|          0|24.04| 19.74| 21.89|24.57|     7.66|  28.36|  20.71|           384.66|\n",
            "|2019|  5|16.05| 81.5|       0.03|24.87| 21.36| 23.12|25.33|     8.26|  29.23|  20.97|           399.29|\n",
            "|2019|  6|14.89|77.62|          0|24.56| 20.19| 22.37|25.08|     6.88|   28.4|  21.54|           387.12|\n",
            "|2019|  7|15.87|79.75|       0.02|25.04| 21.16|  23.1|25.63|     7.96|  29.16|   21.2|           396.37|\n",
            "|2019|  8|16.66|81.25|       0.01|25.58| 21.98| 23.78|25.96|     6.82|   29.3|  22.48|           408.63|\n",
            "|2019|  9|16.36|80.69|       0.04|25.37| 21.65| 23.51|25.81|     7.55|  29.51|  21.96|            405.6|\n",
            "|2019| 10|16.72|81.19|       0.23|25.61| 22.03| 23.82|26.08|     7.38|  29.73|  22.36|           417.98|\n",
            "|2019| 11|16.91|   83|        6.5|25.37|  22.2| 23.79|25.96|     6.42|   28.8|  22.37|           423.37|\n",
            "|2019| 12| 17.4|84.12|       2.04|25.65| 22.73| 24.19|25.94|     5.72|  28.94|  23.23|           425.13|\n",
            "|2019| 13|17.76|86.25|       5.47|25.56| 23.02|  24.3|25.79|     5.72|  28.87|  23.15|            420.6|\n",
            "|2019| 14|17.76|85.06|       4.44| 25.8| 23.01|  24.4|25.94|      5.7|  29.11|   23.4|           424.16|\n",
            "|2019| 15|17.21|83.56|       1.18|25.59| 22.51| 24.05|25.83|     5.62|  28.64|  23.01|           419.64|\n",
            "|2019| 16|17.21|83.81|       3.96|25.53| 22.49| 24.01|25.73|     6.41|  29.25|  22.84|           419.45|\n",
            "|2019| 17|15.32|78.56|       0.15|24.78|  20.6| 22.69|25.09|     7.12|  28.94|  21.81|           395.12|\n",
            "|2019| 18| 14.4|   77|       0.03|24.12| 19.63| 21.88|24.51|     7.67|  28.55|  20.87|           391.56|\n",
            "|2019| 19| 14.1|76.56|          0|23.87| 19.26| 21.56|24.38|     8.29|  28.31|  20.02|            386.9|\n",
            "|2019| 20|15.14|78.25|        0.1|24.58|  20.4| 22.49|24.99|     8.46|  29.05|  20.58|           393.12|\n",
            "+----+---+-----+-----+-----------+-----+------+------+-----+---------+-------+-------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jaffna_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/jaffna_data.csv\",header = True)\n",
        "kandy_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/kandy_data.csv\",header = True)\n",
        "kurunagala_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/kurunagala_data.csv\",header = True)\n",
        "nuwara_eliya_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/nuwara_eliya_data.csv\",header = True)\n",
        "deniyaya_matara_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/matara_data.csv\",header = True)\n",
        "monaragala_data = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/monaragala_data.csv\",header = True)"
      ],
      "metadata": {
        "id": "XVl_YKtZso5r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DateType\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define a function to convert Day of Year to date\n",
        "def doy_to_date(year, doy):\n",
        "    # Construct the date using year and day of year\n",
        "    date = datetime(year, 1, 1) + timedelta(days=int(doy) - 1)\n",
        "    return date.strftime('%Y-%m-%d')\n",
        "\n",
        "# Example usage\n",
        "year = 2019\n",
        "doy = 1\n",
        "date = doy_to_date(year, doy)\n",
        "print(date)  # Output: '2019-01-01'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Ue37uMtUge",
        "outputId": "00933833-c105-493e-baa3-c9512d9adc88"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2019-01-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named df\n",
        "print(jaffna_data.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y5R2Csg4lfT",
        "outputId": "92898aff-2061-4489-ad43-3f89e3f05ec8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('YEAR', 'string'), ('MO', 'string'), ('DY', 'string'), ('QV2M', 'string'), ('RH2M', 'string'), ('PRECTOTCORR', 'string'), ('T2M', 'string'), ('T2MDEW', 'string'), ('T2MWET', 'string'), ('TS', 'string'), ('T2M_RANGE', 'string'), ('T2M_MAX', 'string'), ('T2M_MIN', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data['YEAR'] = colombo_data['YEAR'].astype(int)\n",
        "colombo_data['DOY'] = colombo_data['DOY'].astype(int)"
      ],
      "metadata": {
        "id": "XI5jViXC54Pi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Apply the function to create a new 'Date' column\n",
        "colombo_data['Date'] = colombo_data.apply(lambda row: doy_to_date(row['YEAR'], row['DOY']), axis=1)\n",
        "\n",
        "# Drop the 'YEAR' and 'DOY' columns if needed\n",
        "colombo_data.drop(columns=['YEAR', 'DOY'], inplace=True)\n",
        "\n",
        "# Now your 'Date' column will contain dates in the format 'YYYY-MM-DD'\n",
        "print(colombo_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN8zshI4tUnr",
        "outputId": "9c952b04-8a91-4da0-b94c-c252f01e9222"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    QV2M   RH2M PRECTOTCORR    T2M T2MDEW T2MWET     TS T2M_RANGE T2M_MAX  \\\n",
            "0  15.62     80        0.12   24.8  21.02  22.91  25.29      6.21   28.44   \n",
            "1  15.14   79.5        0.02  24.39  20.51  22.45  25.01      6.54   28.02   \n",
            "2  14.77   78.5        0.01  24.17  20.08  22.13  24.73      6.64   27.94   \n",
            "3  14.47  77.62           0  24.04  19.74  21.89  24.57      7.66   28.36   \n",
            "4  16.05   81.5        0.03  24.87  21.36  23.12  25.33      8.26   29.23   \n",
            "\n",
            "  T2M_MIN ALLSKY_SFC_LW_DWN        Date  \n",
            "0   22.23            407.15  2019-01-01  \n",
            "1   21.48            401.33  2019-01-02  \n",
            "2    21.3            395.24  2019-01-03  \n",
            "3   20.71            384.66  2019-01-04  \n",
            "4   20.97            399.29  2019-01-05  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data = spark.createDataFrame(colombo_data)"
      ],
      "metadata": {
        "id": "BDUjKelh7mSL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "falkAeaZ7y-a",
        "outputId": "f258c20d-4405-49ed-ed2b-d7bc706c76fd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+-----+------+------+-----+---------+-------+-------+-----------------+----------+\n",
            "| QV2M| RH2M|PRECTOTCORR|  T2M|T2MDEW|T2MWET|   TS|T2M_RANGE|T2M_MAX|T2M_MIN|ALLSKY_SFC_LW_DWN|      Date|\n",
            "+-----+-----+-----------+-----+------+------+-----+---------+-------+-------+-----------------+----------+\n",
            "|15.62|   80|       0.12| 24.8| 21.02| 22.91|25.29|     6.21|  28.44|  22.23|           407.15|2019-01-01|\n",
            "|15.14| 79.5|       0.02|24.39| 20.51| 22.45|25.01|     6.54|  28.02|  21.48|           401.33|2019-01-02|\n",
            "|14.77| 78.5|       0.01|24.17| 20.08| 22.13|24.73|     6.64|  27.94|   21.3|           395.24|2019-01-03|\n",
            "|14.47|77.62|          0|24.04| 19.74| 21.89|24.57|     7.66|  28.36|  20.71|           384.66|2019-01-04|\n",
            "|16.05| 81.5|       0.03|24.87| 21.36| 23.12|25.33|     8.26|  29.23|  20.97|           399.29|2019-01-05|\n",
            "|14.89|77.62|          0|24.56| 20.19| 22.37|25.08|     6.88|   28.4|  21.54|           387.12|2019-01-06|\n",
            "|15.87|79.75|       0.02|25.04| 21.16|  23.1|25.63|     7.96|  29.16|   21.2|           396.37|2019-01-07|\n",
            "|16.66|81.25|       0.01|25.58| 21.98| 23.78|25.96|     6.82|   29.3|  22.48|           408.63|2019-01-08|\n",
            "|16.36|80.69|       0.04|25.37| 21.65| 23.51|25.81|     7.55|  29.51|  21.96|            405.6|2019-01-09|\n",
            "|16.72|81.19|       0.23|25.61| 22.03| 23.82|26.08|     7.38|  29.73|  22.36|           417.98|2019-01-10|\n",
            "|16.91|   83|        6.5|25.37|  22.2| 23.79|25.96|     6.42|   28.8|  22.37|           423.37|2019-01-11|\n",
            "| 17.4|84.12|       2.04|25.65| 22.73| 24.19|25.94|     5.72|  28.94|  23.23|           425.13|2019-01-12|\n",
            "|17.76|86.25|       5.47|25.56| 23.02|  24.3|25.79|     5.72|  28.87|  23.15|            420.6|2019-01-13|\n",
            "|17.76|85.06|       4.44| 25.8| 23.01|  24.4|25.94|      5.7|  29.11|   23.4|           424.16|2019-01-14|\n",
            "|17.21|83.56|       1.18|25.59| 22.51| 24.05|25.83|     5.62|  28.64|  23.01|           419.64|2019-01-15|\n",
            "|17.21|83.81|       3.96|25.53| 22.49| 24.01|25.73|     6.41|  29.25|  22.84|           419.45|2019-01-16|\n",
            "|15.32|78.56|       0.15|24.78|  20.6| 22.69|25.09|     7.12|  28.94|  21.81|           395.12|2019-01-17|\n",
            "| 14.4|   77|       0.03|24.12| 19.63| 21.88|24.51|     7.67|  28.55|  20.87|           391.56|2019-01-18|\n",
            "| 14.1|76.56|          0|23.87| 19.26| 21.56|24.38|     8.29|  28.31|  20.02|            386.9|2019-01-19|\n",
            "|15.14|78.25|        0.1|24.58|  20.4| 22.49|24.99|     8.46|  29.05|  20.58|           393.12|2019-01-20|\n",
            "+-----+-----+-----------+-----+------+------+-----+---------+-------+-------+-----------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Assuming colombo_data is your PySpark DataFrame and you want to drop the 'YEAR' and 'DOY' columns\n",
        "colombo_data = colombo_data.drop('T2MDEW', 'T2MWET', 'T2M_RANGE', 'T2M_MAX', 'T2M_MIN', 'ALLSKY_SFC_LW_DWN')\n"
      ],
      "metadata": {
        "id": "kCKR2R8j8SFM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdkeMaY___yf",
        "outputId": "02676e18-3ca1-4db1-fd35-455541c60c50"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+-----+-----+----------+\n",
            "| QV2M| RH2M|PRECTOTCORR|  T2M|   TS|      Date|\n",
            "+-----+-----+-----------+-----+-----+----------+\n",
            "|15.62|   80|       0.12| 24.8|25.29|2019-01-01|\n",
            "|15.14| 79.5|       0.02|24.39|25.01|2019-01-02|\n",
            "|14.77| 78.5|       0.01|24.17|24.73|2019-01-03|\n",
            "|14.47|77.62|          0|24.04|24.57|2019-01-04|\n",
            "|16.05| 81.5|       0.03|24.87|25.33|2019-01-05|\n",
            "|14.89|77.62|          0|24.56|25.08|2019-01-06|\n",
            "|15.87|79.75|       0.02|25.04|25.63|2019-01-07|\n",
            "|16.66|81.25|       0.01|25.58|25.96|2019-01-08|\n",
            "|16.36|80.69|       0.04|25.37|25.81|2019-01-09|\n",
            "|16.72|81.19|       0.23|25.61|26.08|2019-01-10|\n",
            "|16.91|   83|        6.5|25.37|25.96|2019-01-11|\n",
            "| 17.4|84.12|       2.04|25.65|25.94|2019-01-12|\n",
            "|17.76|86.25|       5.47|25.56|25.79|2019-01-13|\n",
            "|17.76|85.06|       4.44| 25.8|25.94|2019-01-14|\n",
            "|17.21|83.56|       1.18|25.59|25.83|2019-01-15|\n",
            "|17.21|83.81|       3.96|25.53|25.73|2019-01-16|\n",
            "|15.32|78.56|       0.15|24.78|25.09|2019-01-17|\n",
            "| 14.4|   77|       0.03|24.12|24.51|2019-01-18|\n",
            "| 14.1|76.56|          0|23.87|24.38|2019-01-19|\n",
            "|15.14|78.25|        0.1|24.58|24.99|2019-01-20|\n",
            "+-----+-----+-----------+-----+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data = colombo_data.withColumnRenamed('QV2M', 'Specific Humidity')\n",
        "colombo_data = colombo_data.withColumnRenamed('RH2M', 'Relative Humidity')"
      ],
      "metadata": {
        "id": "UjKPrSKsCE98"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMa81DIzCdQp",
        "outputId": "4730cac6-8888-43f2-93f7-ee03cbcf875e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+-----------+-----+-----+----------+\n",
            "|Specific Humidity|Relative Humidity|PRECTOTCORR|  T2M|   TS|      Date|\n",
            "+-----------------+-----------------+-----------+-----+-----+----------+\n",
            "|            15.62|               80|       0.12| 24.8|25.29|2019-01-01|\n",
            "|            15.14|             79.5|       0.02|24.39|25.01|2019-01-02|\n",
            "|            14.77|             78.5|       0.01|24.17|24.73|2019-01-03|\n",
            "|            14.47|            77.62|          0|24.04|24.57|2019-01-04|\n",
            "|            16.05|             81.5|       0.03|24.87|25.33|2019-01-05|\n",
            "|            14.89|            77.62|          0|24.56|25.08|2019-01-06|\n",
            "|            15.87|            79.75|       0.02|25.04|25.63|2019-01-07|\n",
            "|            16.66|            81.25|       0.01|25.58|25.96|2019-01-08|\n",
            "|            16.36|            80.69|       0.04|25.37|25.81|2019-01-09|\n",
            "|            16.72|            81.19|       0.23|25.61|26.08|2019-01-10|\n",
            "|            16.91|               83|        6.5|25.37|25.96|2019-01-11|\n",
            "|             17.4|            84.12|       2.04|25.65|25.94|2019-01-12|\n",
            "|            17.76|            86.25|       5.47|25.56|25.79|2019-01-13|\n",
            "|            17.76|            85.06|       4.44| 25.8|25.94|2019-01-14|\n",
            "|            17.21|            83.56|       1.18|25.59|25.83|2019-01-15|\n",
            "|            17.21|            83.81|       3.96|25.53|25.73|2019-01-16|\n",
            "|            15.32|            78.56|       0.15|24.78|25.09|2019-01-17|\n",
            "|             14.4|               77|       0.03|24.12|24.51|2019-01-18|\n",
            "|             14.1|            76.56|          0|23.87|24.38|2019-01-19|\n",
            "|            15.14|            78.25|        0.1|24.58|24.99|2019-01-20|\n",
            "+-----------------+-----------------+-----------+-----+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}