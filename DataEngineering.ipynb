{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcbpHvaWy3VNiSZcnN/9N4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esandu-Meth-Obadaarachchi/HCHO-level-Time-series-forecasting/blob/main/DataEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qrop8Gkb26l8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pu8h4P_4F5_",
        "outputId": "8aa7210b-bbae-47d2-8dd4-42983e65cbbf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=66465a1e48c20464c22c2f2f89e64d2e748ad500bd5661991a09e856f4e34082\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubPwiRoX4Hdt",
        "outputId": "5518c01c-86a0-47b2-d962-cb58d7b8af6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql  as pyspark_sql\n",
        "import pyspark.sql.types as pyspark_types\n",
        "import pyspark.sql.functions  as pyspark_functions\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.functions import col, regexp_replace, when\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, StringType"
      ],
      "metadata": {
        "id": "8sRZoTMQ4JjT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = pyspark_sql.SparkSession.builder.getOrCreate()\n"
      ],
      "metadata": {
        "id": "gUaeQtYF4Lsj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define column names and data types\n",
        "schema = StructType([\n",
        "    StructField(\"HCHO reading\", DoubleType(), True),\n",
        "    StructField(\"Location\", StringType(), True),\n",
        "    StructField(\"Current Date\", StringType(), True),\n",
        "    StructField(\"Next Date\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Load the data for 'Colombo Proper', 'Deniyaya, Matara', 'Nuwara Eliya Proper' with specified column names\n",
        "col_mat_nuw_df = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/col_mat_nuw_output.csv\", header=False, schema=schema)\n",
        "\n",
        "# Load the data for 'Bibile, Monaragala', 'Kurunegala Proper', 'Jaffna Proper' with specified column names\n",
        "mon_kur_jaf_df = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/mon_kur_jaf_output.csv\", header=False, schema=schema)\n",
        "\n",
        "# Load the data for 'Kandy Proper' with specified column names\n",
        "kan_df = spark.read.csv(\"/content/drive/MyDrive/data engineering CW/kan_output.csv\", header=False, schema=schema)\n"
      ],
      "metadata": {
        "id": "uupAwsBU4eff"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_mat_nuw_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOBrmQLf4kMA",
        "outputId": "172a1aaa-64cd-4772-9299-7972187739fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+------------+----------+\n",
            "|        HCHO reading|      Location|Current Date| Next Date|\n",
            "+--------------------+--------------+------------+----------+\n",
            "|1.969834395781014...|Colombo Proper|  2019-01-01|2019-01-02|\n",
            "|2.625522171968594...|Colombo Proper|  2019-01-02|2019-01-03|\n",
            "|9.852118897938794E-5|Colombo Proper|  2019-01-03|2019-01-04|\n",
            "|2.099320518114242E-4|Colombo Proper|  2019-01-04|2019-01-05|\n",
            "|1.785337298892930...|Colombo Proper|  2019-01-05|2019-01-06|\n",
            "|1.082296700235670...|Colombo Proper|  2019-01-06|2019-01-07|\n",
            "|3.926829280477309...|Colombo Proper|  2019-01-07|2019-01-08|\n",
            "|9.153156350685351E-5|Colombo Proper|  2019-01-08|2019-01-09|\n",
            "|1.205978992853015...|Colombo Proper|  2019-01-09|2019-01-10|\n",
            "|1.297723562983258...|Colombo Proper|  2019-01-10|2019-01-11|\n",
            "|2.239188166801278...|Colombo Proper|  2019-01-11|2019-01-12|\n",
            "|1.569418094178759...|Colombo Proper|  2019-01-12|2019-01-13|\n",
            "|                NULL|Colombo Proper|  2019-01-13|2019-01-14|\n",
            "|1.336291906862603...|Colombo Proper|  2019-01-14|2019-01-15|\n",
            "|6.374417842690063E-5|Colombo Proper|  2019-01-15|2019-01-16|\n",
            "|1.181062250815020...|Colombo Proper|  2019-01-16|2019-01-17|\n",
            "|2.472555222423037...|Colombo Proper|  2019-01-17|2019-01-18|\n",
            "|3.667525352047757E-5|Colombo Proper|  2019-01-18|2019-01-19|\n",
            "|4.057500868150313E-4|Colombo Proper|  2019-01-19|2019-01-20|\n",
            "|1.687856216479722...|Colombo Proper|  2019-01-20|2019-01-21|\n",
            "+--------------------+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for 'Colombo Proper' and create a new DataFrame\n",
        "colombo_df = col_mat_nuw_df.filter(col(\"Location\") == \"Colombo Proper\")\n",
        "\n",
        "# Filter data for 'Deniyaya, Matara' and create a new DataFrame\n",
        "deniyaya_matara_df = col_mat_nuw_df.filter(col(\"Location\") == \"Deniyaya, Matara\")\n",
        "\n",
        "# Filter data for 'Nuwara Eliya Proper' and create a new DataFrame\n",
        "nuwara_eliya_df = col_mat_nuw_df.filter(col(\"Location\") == \"Nuwara Eliya Proper\")\n",
        "\n",
        "# Filter data for 'Bibile, Monaragala' and create a new DataFrame\n",
        "bibile_monaragala_df = mon_kur_jaf_df.filter(col(\"Location\") == \"Bibile, Monaragala\")\n",
        "\n",
        "# Filter data for 'Kurunegala Proper' and create a new DataFrame\n",
        "kurunegala_df = mon_kur_jaf_df.filter(col(\"Location\") == \"Kurunegala Proper\")\n",
        "\n",
        "# Filter data for 'Jaffna Proper' and create a new DataFrame\n",
        "jaffna_df = mon_kur_jaf_df.filter(col(\"Location\") == \"Jaffna Proper\")\n",
        "\n",
        "# Filter data for 'Kandy Proper' and create a new DataFrame\n",
        "kandy_df = kan_df.filter(col(\"Location\") == \"Kandy Proper\")\n",
        "\n",
        "# Show sample data for verification\n",
        "colombo_df.show(5)\n",
        "deniyaya_matara_df.show(5)\n",
        "nuwara_eliya_df.show(5)\n",
        "bibile_monaragala_df.show(5)\n",
        "kurunegala_df.show(5)\n",
        "jaffna_df.show(5)\n",
        "kandy_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY2D08DP74Vc",
        "outputId": "9f80f610-9cf0-4aac-879e-08ad7394c8ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+------------+----------+\n",
            "|        HCHO reading|      Location|Current Date| Next Date|\n",
            "+--------------------+--------------+------------+----------+\n",
            "|1.969834395781014...|Colombo Proper|  2019-01-01|2019-01-02|\n",
            "|2.625522171968594...|Colombo Proper|  2019-01-02|2019-01-03|\n",
            "|9.852118897938794E-5|Colombo Proper|  2019-01-03|2019-01-04|\n",
            "|2.099320518114242E-4|Colombo Proper|  2019-01-04|2019-01-05|\n",
            "|1.785337298892930...|Colombo Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+--------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+----------------+------------+----------+\n",
            "|        HCHO reading|        Location|Current Date| Next Date|\n",
            "+--------------------+----------------+------------+----------+\n",
            "|                NULL|Deniyaya, Matara|  2019-01-01|2019-01-02|\n",
            "|5.803530712000793E-6|Deniyaya, Matara|  2019-01-02|2019-01-03|\n",
            "|2.362357772653922...|Deniyaya, Matara|  2019-01-03|2019-01-04|\n",
            "|6.437245753953118E-5|Deniyaya, Matara|  2019-01-04|2019-01-05|\n",
            "|5.349707092885017E-5|Deniyaya, Matara|  2019-01-05|2019-01-06|\n",
            "+--------------------+----------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+-------------------+------------+----------+\n",
            "|        HCHO reading|           Location|Current Date| Next Date|\n",
            "+--------------------+-------------------+------------+----------+\n",
            "|                NULL|Nuwara Eliya Proper|  2019-01-01|2019-01-02|\n",
            "|                NULL|Nuwara Eliya Proper|  2019-01-02|2019-01-03|\n",
            "|1.908293886956784...|Nuwara Eliya Proper|  2019-01-03|2019-01-04|\n",
            "|5.097625917127737...|Nuwara Eliya Proper|  2019-01-04|2019-01-05|\n",
            "|6.456645496655256E-5|Nuwara Eliya Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+-------------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------------------+------------+----------+\n",
            "|        HCHO reading|          Location|Current Date| Next Date|\n",
            "+--------------------+------------------+------------+----------+\n",
            "|                NULL|Bibile, Monaragala|  2019-01-01|2019-01-02|\n",
            "|1.919914652467399E-5|Bibile, Monaragala|  2019-01-02|2019-01-03|\n",
            "|2.811447935930283...|Bibile, Monaragala|  2019-01-03|2019-01-04|\n",
            "|3.747998184385943E-5|Bibile, Monaragala|  2019-01-04|2019-01-05|\n",
            "|-1.79826087934531...|Bibile, Monaragala|  2019-01-05|2019-01-06|\n",
            "+--------------------+------------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+-----------------+------------+----------+\n",
            "|        HCHO reading|         Location|Current Date| Next Date|\n",
            "+--------------------+-----------------+------------+----------+\n",
            "|8.829725542537962E-5|Kurunegala Proper|  2019-01-01|2019-01-02|\n",
            "|1.370787402778218...|Kurunegala Proper|  2019-01-02|2019-01-03|\n",
            "|1.480085027113037E-4|Kurunegala Proper|  2019-01-03|2019-01-04|\n",
            "|-2.04637905973554...|Kurunegala Proper|  2019-01-04|2019-01-05|\n",
            "|2.489134742856164E-4|Kurunegala Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+-----------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+-------------+------------+----------+\n",
            "|        HCHO reading|     Location|Current Date| Next Date|\n",
            "+--------------------+-------------+------------+----------+\n",
            "|5.830909719406619E-5|Jaffna Proper|  2019-01-01|2019-01-02|\n",
            "|1.017952795536237...|Jaffna Proper|  2019-01-02|2019-01-03|\n",
            "| 3.93133105404262E-5|Jaffna Proper|  2019-01-03|2019-01-04|\n",
            "|-2.38398465761844...|Jaffna Proper|  2019-01-04|2019-01-05|\n",
            "|1.589137302293815...|Jaffna Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+-------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------------+------------+----------+\n",
            "|        HCHO reading|    Location|Current Date| Next Date|\n",
            "+--------------------+------------+------------+----------+\n",
            "|1.760713459877335...|Kandy Proper|  2019-01-01|2019-01-02|\n",
            "|9.220391253917748E-5|Kandy Proper|  2019-01-02|2019-01-03|\n",
            "|                NULL|Kandy Proper|  2019-01-03|2019-01-04|\n",
            "|1.908681983853839...|Kandy Proper|  2019-01-04|2019-01-05|\n",
            "|1.219517840206744...|Kandy Proper|  2019-01-05|2019-01-06|\n",
            "+--------------------+------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colombo_df.select(\"HCHO reading\").describe().show()\n",
        "\n",
        "deniyaya_matara_df.select(\"HCHO reading\").describe().show()\n",
        "\n",
        "# Summary statistics for 'Nuwara Eliya Proper'\n",
        "nuwara_eliya_df.select(\"HCHO reading\").describe().show()\n",
        "\n",
        "# Summary statistics for 'Bibile, Monaragala'\n",
        "bibile_monaragala_df.select(\"HCHO reading\").describe().show()\n",
        "\n",
        "# Summary statistics for 'Kurunegala Proper'\n",
        "kurunegala_df.select(\"HCHO reading\").describe().show()\n",
        "\n",
        "# Summary statistics for 'Jaffna Proper'\n",
        "jaffna_df.select(\"HCHO reading\").describe().show()\n",
        "\n",
        "# Summary statistics for 'Kandy Proper'\n",
        "kandy_df.select(\"HCHO reading\").describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXmFEEK44mHy",
        "outputId": "3298bd04-3bec-44c5-abf4-5c2b9d7ee98a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                1339|\n",
            "|   mean|1.585714042136032...|\n",
            "| stddev|9.928801616320847E-5|\n",
            "|    min|-2.29102592175331...|\n",
            "|    max|6.500630612512026E-4|\n",
            "+-------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                 979|\n",
            "|   mean|9.165608034246397E-5|\n",
            "| stddev|9.717767267758977E-5|\n",
            "|    min|-2.59296176552668...|\n",
            "|    max|8.997101837438971E-4|\n",
            "+-------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                 741|\n",
            "|   mean|8.792586073767327E-5|\n",
            "| stddev|8.366257795578253E-5|\n",
            "|    min|-1.78604299088136...|\n",
            "|    max|4.191362201414739E-4|\n",
            "+-------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                1131|\n",
            "|   mean|1.264313797412045...|\n",
            "| stddev|9.402251427407129E-5|\n",
            "|    min|-2.39045708440244...|\n",
            "|    max|5.348281140823137E-4|\n",
            "+-------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                1234|\n",
            "|   mean|1.340202702666862E-4|\n",
            "| stddev|8.677375232539984E-5|\n",
            "|    min|-1.57093759305910...|\n",
            "|    max|5.032967399339503E-4|\n",
            "+-------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                1461|\n",
            "|   mean|1.088086650369041E-4|\n",
            "| stddev|7.844332899390023E-5|\n",
            "|    min|-3.52473024357239...|\n",
            "|    max|5.837611392919413E-4|\n",
            "+-------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|summary|        HCHO reading|\n",
            "+-------+--------------------+\n",
            "|  count|                1033|\n",
            "|   mean|1.063760956208845...|\n",
            "| stddev|9.202571862518035E-5|\n",
            "|    min|-2.99702863135199...|\n",
            "|    max|7.051621763962024E-4|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ac_LDpXN8x1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "# Count null values for 'Colombo Proper'\n",
        "colombo_null_count = colombo_df.select([col(c).isNull().cast(\"int\").alias(c) for c in colombo_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Count null values for 'Deniyaya, Matara'\n",
        "deniyaya_matara_null_count = deniyaya_matara_df.select([col(c).isNull().cast(\"int\").alias(c) for c in deniyaya_matara_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Count null values for 'Nuwara Eliya Proper'\n",
        "nuwara_eliya_null_count = nuwara_eliya_df.select([col(c).isNull().cast(\"int\").alias(c) for c in nuwara_eliya_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Count null values for 'Bibile, Monaragala'\n",
        "bibile_monaragala_null_count = bibile_monaragala_df.select([col(c).isNull().cast(\"int\").alias(c) for c in bibile_monaragala_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Count null values for 'Kurunegala Proper'\n",
        "kurunegala_null_count = kurunegala_df.select([col(c).isNull().cast(\"int\").alias(c) for c in kurunegala_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Count null values for 'Jaffna Proper'\n",
        "jaffna_null_count = jaffna_df.select([col(c).isNull().cast(\"int\").alias(c) for c in jaffna_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Count null values for 'Kandy Proper'\n",
        "kandy_null_count = kandy_df.select([col(c).isNull().cast(\"int\").alias(c) for c in kandy_df.columns]).agg(sum(col(\"HCHO reading\")).alias(\"Null Count\")).collect()[0][\"Null Count\"]\n",
        "\n",
        "# Print null counts for each city\n",
        "print(\"Null Counts for Colombo Proper:\", colombo_null_count)\n",
        "print(\"Null Counts for Deniyaya, Matara:\", deniyaya_matara_null_count)\n",
        "print(\"Null Counts for Nuwara Eliya Proper:\", nuwara_eliya_null_count)\n",
        "print(\"Null Counts for Bibile, Monaragala:\", bibile_monaragala_null_count)\n",
        "print(\"Null Counts for Kurunegala Proper:\", kurunegala_null_count)\n",
        "print(\"Null Counts for Jaffna Proper:\", jaffna_null_count)\n",
        "print(\"Null Counts for Kandy Proper:\", kandy_null_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_28E_cPl8x3u",
        "outputId": "423b1f01-2a2d-4fdc-acbe-1a5089a87d01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null Counts for Colombo Proper: 487\n",
            "Null Counts for Deniyaya, Matara: 847\n",
            "Null Counts for Nuwara Eliya Proper: 1085\n",
            "Null Counts for Bibile, Monaragala: 695\n",
            "Null Counts for Kurunegala Proper: 592\n",
            "Null Counts for Jaffna Proper: 365\n",
            "Null Counts for Kandy Proper: 793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql.functions import mean, lag, lead, col, when\n",
        "\n",
        "# Define window specification\n",
        "windowSpec = Window.orderBy(\"Current Date\")\n",
        "\n",
        "# Calculate lag and lead values\n",
        "lag_value = lag(\"HCHO reading\").over(windowSpec)\n",
        "lead_value = lead(\"HCHO reading\").over(windowSpec)\n",
        "\n",
        "# Replace missing values with the mean of neighboring values\n",
        "deniyaya_matara_df = deniyaya_matara_df.withColumn(\"HCHO reading\",\n",
        "                                    when(col(\"HCHO reading\").isNull(),\n",
        "                                         (lag_value + lead_value) / 2).otherwise(col(\"HCHO reading\")))\n",
        "\n",
        "# Show the resulting DataFrame with replaced values\n",
        "deniyaya_matara_df.show()"
      ],
      "metadata": {
        "id": "ayebKXpK8x4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "def impute_missing_values_linear_regression(df):\n",
        "    # Drop rows with missing values as Linear Regression cannot handle them directly\n",
        "    df = df.dropna(subset=[\"HCHO reading\"])\n",
        "\n",
        "    # Convert string columns to numerical using StringIndexer\n",
        "    location_indexer = StringIndexer(inputCol=\"Location\", outputCol=\"LocationIndex\")\n",
        "    date_indexer = StringIndexer(inputCol=\"Current Date\", outputCol=\"DateIndex\")\n",
        "    next_date_indexer = StringIndexer(inputCol=\"Next Date\", outputCol=\"NextDateIndex\")\n",
        "\n",
        "    # Fit StringIndexer models\n",
        "    location_indexer_model = location_indexer.fit(df)\n",
        "    date_indexer_model = date_indexer.fit(df)\n",
        "    next_date_indexer_model = next_date_indexer.fit(df)\n",
        "\n",
        "    # Apply StringIndexer models to DataFrame\n",
        "    df = location_indexer_model.transform(df)\n",
        "    df = date_indexer_model.transform(df)\n",
        "    df = next_date_indexer_model.transform(df)\n",
        "\n",
        "    # Assemble features\n",
        "    assembler = VectorAssembler(inputCols=[\"LocationIndex\", \"DateIndex\", \"NextDateIndex\"], outputCol=\"features\")\n",
        "    df_assembled = assembler.transform(df)\n",
        "\n",
        "    # Train a linear regression model\n",
        "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"HCHO reading\")\n",
        "    lr_model = lr.fit(df_assembled)\n",
        "\n",
        "    # Apply the model to predict missing values\n",
        "    predictions = lr_model.transform(df_assembled)\n",
        "\n",
        "    # Replace missing values with predicted values\n",
        "    return predictions.withColumn(\"HCHO reading\",\n",
        "                                   when(col(\"HCHO reading\").isNull(),\n",
        "                                        col(\"prediction\")).otherwise(col(\"HCHO reading\")))\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "colombo_df = impute_missing_values_linear_regression(colombo_df)\n",
        "deniyaya_matara_df = impute_missing_values_linear_regression(deniyaya_matara_df)\n",
        "nuwara_eliya_df = impute_missing_values_linear_regression(nuwara_eliya_df)\n",
        "bibile_monaragala_df = impute_missing_values_linear_regression(bibile_monaragala_df)\n",
        "kurunegala_df = impute_missing_values_linear_regression(kurunegala_df)\n",
        "jaffna_df = impute_missing_values_linear_regression(jaffna_df)\n",
        "kandy_df = impute_missing_values_linear_regression(kandy_df)"
      ],
      "metadata": {
        "id": "50zkbWP68x6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YRe2zG9v8x8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mABj0mFz8x_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibCfFPWY8yCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6OFrnIF08yD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYZqrspy8yFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dKguLhs8yG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3X3Sv5A8yIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcYN6-WJ8yJ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}